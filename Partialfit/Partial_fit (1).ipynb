{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(r\"C:\\Users\\reekithak\\Downloads\\drugs.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * from train_set1\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>emb0</th>\n",
       "      <th>emb1</th>\n",
       "      <th>emb2</th>\n",
       "      <th>emb3</th>\n",
       "      <th>emb4</th>\n",
       "      <th>emb5</th>\n",
       "      <th>emb6</th>\n",
       "      <th>emb7</th>\n",
       "      <th>emb8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb23</th>\n",
       "      <th>emb24</th>\n",
       "      <th>emb25</th>\n",
       "      <th>emb26</th>\n",
       "      <th>emb27</th>\n",
       "      <th>emb28</th>\n",
       "      <th>emb29</th>\n",
       "      <th>emb30</th>\n",
       "      <th>emb31</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3081361</td>\n",
       "      <td>5.994874</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.878794</td>\n",
       "      <td>13.842925</td>\n",
       "      <td>-2.137559</td>\n",
       "      <td>4.200539</td>\n",
       "      <td>1.482366</td>\n",
       "      <td>-6.032686</td>\n",
       "      <td>-7.982576</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.445458</td>\n",
       "      <td>6.116971</td>\n",
       "      <td>-3.942830</td>\n",
       "      <td>1.511006</td>\n",
       "      <td>-7.021651</td>\n",
       "      <td>3.495900</td>\n",
       "      <td>-3.484098</td>\n",
       "      <td>-5.298349</td>\n",
       "      <td>1.864513</td>\n",
       "      <td>1D4H,1FLT,1Y6A,1EVT,1IVO,1Y6A,1FLT,1JU5,2XB7,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5327236</td>\n",
       "      <td>0.149257</td>\n",
       "      <td>-1.246052</td>\n",
       "      <td>-0.178906</td>\n",
       "      <td>-1.036862</td>\n",
       "      <td>-0.676611</td>\n",
       "      <td>0.339497</td>\n",
       "      <td>0.336225</td>\n",
       "      <td>-1.316193</td>\n",
       "      <td>-0.219831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>-0.268545</td>\n",
       "      <td>-0.152387</td>\n",
       "      <td>1.113073</td>\n",
       "      <td>0.521675</td>\n",
       "      <td>-0.142568</td>\n",
       "      <td>1.219517</td>\n",
       "      <td>0.369882</td>\n",
       "      <td>1.251220</td>\n",
       "      <td>1D4H,1D4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5327235</td>\n",
       "      <td>0.439556</td>\n",
       "      <td>-1.262701</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>-0.972333</td>\n",
       "      <td>-0.458843</td>\n",
       "      <td>0.326891</td>\n",
       "      <td>0.134291</td>\n",
       "      <td>-1.255150</td>\n",
       "      <td>-0.147705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581495</td>\n",
       "      <td>-0.266222</td>\n",
       "      <td>0.081007</td>\n",
       "      <td>1.396610</td>\n",
       "      <td>0.737672</td>\n",
       "      <td>-0.294349</td>\n",
       "      <td>1.111987</td>\n",
       "      <td>0.369131</td>\n",
       "      <td>0.853854</td>\n",
       "      <td>1D4H,1D4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5327234</td>\n",
       "      <td>0.165102</td>\n",
       "      <td>-0.990787</td>\n",
       "      <td>-0.182518</td>\n",
       "      <td>-0.428134</td>\n",
       "      <td>-0.623397</td>\n",
       "      <td>0.228414</td>\n",
       "      <td>0.327499</td>\n",
       "      <td>-0.973677</td>\n",
       "      <td>-0.004820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518435</td>\n",
       "      <td>-0.546104</td>\n",
       "      <td>-0.041725</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>-0.058730</td>\n",
       "      <td>-0.615353</td>\n",
       "      <td>0.724715</td>\n",
       "      <td>-0.331381</td>\n",
       "      <td>0.386585</td>\n",
       "      <td>1D4H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3009319</td>\n",
       "      <td>0.429637</td>\n",
       "      <td>-1.359506</td>\n",
       "      <td>-0.271043</td>\n",
       "      <td>-1.444596</td>\n",
       "      <td>-0.640501</td>\n",
       "      <td>0.407794</td>\n",
       "      <td>0.178657</td>\n",
       "      <td>-1.417959</td>\n",
       "      <td>0.608096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833636</td>\n",
       "      <td>-0.304354</td>\n",
       "      <td>-0.142579</td>\n",
       "      <td>1.519212</td>\n",
       "      <td>0.663829</td>\n",
       "      <td>-0.184633</td>\n",
       "      <td>1.676059</td>\n",
       "      <td>0.260564</td>\n",
       "      <td>0.827677</td>\n",
       "      <td>1D4H,1D4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483776</th>\n",
       "      <td>76329005</td>\n",
       "      <td>1.732422</td>\n",
       "      <td>-0.956258</td>\n",
       "      <td>0.284059</td>\n",
       "      <td>-0.252035</td>\n",
       "      <td>-1.539681</td>\n",
       "      <td>0.660309</td>\n",
       "      <td>-3.159835</td>\n",
       "      <td>0.014737</td>\n",
       "      <td>-1.554970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038092</td>\n",
       "      <td>1.142181</td>\n",
       "      <td>-0.903141</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>-1.768150</td>\n",
       "      <td>1.584594</td>\n",
       "      <td>-1.765474</td>\n",
       "      <td>3.958736</td>\n",
       "      <td>-1.745606</td>\n",
       "      <td>1CKP,4EUT,4EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483777</th>\n",
       "      <td>76310925</td>\n",
       "      <td>0.588260</td>\n",
       "      <td>-0.088623</td>\n",
       "      <td>-0.095146</td>\n",
       "      <td>0.335471</td>\n",
       "      <td>-1.006141</td>\n",
       "      <td>1.088541</td>\n",
       "      <td>-0.397716</td>\n",
       "      <td>-0.518883</td>\n",
       "      <td>-0.258877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166949</td>\n",
       "      <td>-0.386585</td>\n",
       "      <td>-0.166143</td>\n",
       "      <td>1.426241</td>\n",
       "      <td>-1.358101</td>\n",
       "      <td>0.470329</td>\n",
       "      <td>-0.109361</td>\n",
       "      <td>0.543758</td>\n",
       "      <td>-0.110977</td>\n",
       "      <td>4EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483778</th>\n",
       "      <td>76321827</td>\n",
       "      <td>1.959692</td>\n",
       "      <td>-1.192661</td>\n",
       "      <td>0.574516</td>\n",
       "      <td>0.228381</td>\n",
       "      <td>-1.301414</td>\n",
       "      <td>0.818449</td>\n",
       "      <td>-2.651658</td>\n",
       "      <td>0.468997</td>\n",
       "      <td>-1.502997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061165</td>\n",
       "      <td>0.291502</td>\n",
       "      <td>-1.005161</td>\n",
       "      <td>0.029639</td>\n",
       "      <td>-2.543695</td>\n",
       "      <td>1.912899</td>\n",
       "      <td>-1.333267</td>\n",
       "      <td>3.516484</td>\n",
       "      <td>-1.666943</td>\n",
       "      <td>1CKP,4EUT,4EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483779</th>\n",
       "      <td>76325463</td>\n",
       "      <td>-0.024522</td>\n",
       "      <td>-0.270010</td>\n",
       "      <td>-0.038519</td>\n",
       "      <td>0.552287</td>\n",
       "      <td>-0.477502</td>\n",
       "      <td>0.755523</td>\n",
       "      <td>-0.636920</td>\n",
       "      <td>-0.295423</td>\n",
       "      <td>-0.029023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236449</td>\n",
       "      <td>0.637996</td>\n",
       "      <td>-0.411944</td>\n",
       "      <td>1.028800</td>\n",
       "      <td>-1.102756</td>\n",
       "      <td>-0.049067</td>\n",
       "      <td>-0.177718</td>\n",
       "      <td>0.584480</td>\n",
       "      <td>-0.675975</td>\n",
       "      <td>4EUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483780</th>\n",
       "      <td>76332688</td>\n",
       "      <td>0.164486</td>\n",
       "      <td>-0.263638</td>\n",
       "      <td>0.402520</td>\n",
       "      <td>0.506924</td>\n",
       "      <td>-1.092456</td>\n",
       "      <td>0.828230</td>\n",
       "      <td>-0.684478</td>\n",
       "      <td>-0.240556</td>\n",
       "      <td>-0.167944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135953</td>\n",
       "      <td>-0.643398</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>1.228267</td>\n",
       "      <td>-1.167841</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>-0.085452</td>\n",
       "      <td>0.290832</td>\n",
       "      <td>-0.669892</td>\n",
       "      <td>4EUT,4EUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483781 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cid      emb0      emb1      emb2       emb3      emb4      emb5  \\\n",
       "0        3081361  5.994874  0.500049  8.878794  13.842925 -2.137559  4.200539   \n",
       "1        5327236  0.149257 -1.246052 -0.178906  -1.036862 -0.676611  0.339497   \n",
       "2        5327235  0.439556 -1.262701  0.007303  -0.972333 -0.458843  0.326891   \n",
       "3        5327234  0.165102 -0.990787 -0.182518  -0.428134 -0.623397  0.228414   \n",
       "4        3009319  0.429637 -1.359506 -0.271043  -1.444596 -0.640501  0.407794   \n",
       "...          ...       ...       ...       ...        ...       ...       ...   \n",
       "483776  76329005  1.732422 -0.956258  0.284059  -0.252035 -1.539681  0.660309   \n",
       "483777  76310925  0.588260 -0.088623 -0.095146   0.335471 -1.006141  1.088541   \n",
       "483778  76321827  1.959692 -1.192661  0.574516   0.228381 -1.301414  0.818449   \n",
       "483779  76325463 -0.024522 -0.270010 -0.038519   0.552287 -0.477502  0.755523   \n",
       "483780  76332688  0.164486 -0.263638  0.402520   0.506924 -1.092456  0.828230   \n",
       "\n",
       "            emb6      emb7      emb8  ...     emb23     emb24     emb25  \\\n",
       "0       1.482366 -6.032686 -7.982576  ... -7.445458  6.116971 -3.942830   \n",
       "1       0.336225 -1.316193 -0.219831  ...  0.476498 -0.268545 -0.152387   \n",
       "2       0.134291 -1.255150 -0.147705  ...  0.581495 -0.266222  0.081007   \n",
       "3       0.327499 -0.973677 -0.004820  ...  0.518435 -0.546104 -0.041725   \n",
       "4       0.178657 -1.417959  0.608096  ...  0.833636 -0.304354 -0.142579   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "483776 -3.159835  0.014737 -1.554970  ... -0.038092  1.142181 -0.903141   \n",
       "483777 -0.397716 -0.518883 -0.258877  ... -0.166949 -0.386585 -0.166143   \n",
       "483778 -2.651658  0.468997 -1.502997  ...  0.061165  0.291502 -1.005161   \n",
       "483779 -0.636920 -0.295423 -0.029023  ...  0.236449  0.637996 -0.411944   \n",
       "483780 -0.684478 -0.240556 -0.167944  ... -0.135953 -0.643398  0.112723   \n",
       "\n",
       "           emb26     emb27     emb28     emb29     emb30     emb31  \\\n",
       "0       1.511006 -7.021651  3.495900 -3.484098 -5.298349  1.864513   \n",
       "1       1.113073  0.521675 -0.142568  1.219517  0.369882  1.251220   \n",
       "2       1.396610  0.737672 -0.294349  1.111987  0.369131  0.853854   \n",
       "3       0.908058 -0.058730 -0.615353  0.724715 -0.331381  0.386585   \n",
       "4       1.519212  0.663829 -0.184633  1.676059  0.260564  0.827677   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "483776  0.014471 -1.768150  1.584594 -1.765474  3.958736 -1.745606   \n",
       "483777  1.426241 -1.358101  0.470329 -0.109361  0.543758 -0.110977   \n",
       "483778  0.029639 -2.543695  1.912899 -1.333267  3.516484 -1.666943   \n",
       "483779  1.028800 -1.102756 -0.049067 -0.177718  0.584480 -0.675975   \n",
       "483780  1.228267 -1.167841  0.024221 -0.085452  0.290832 -0.669892   \n",
       "\n",
       "                                                   target  \n",
       "0       1D4H,1FLT,1Y6A,1EVT,1IVO,1Y6A,1FLT,1JU5,2XB7,2...  \n",
       "1                                               1D4H,1D4K  \n",
       "2                                               1D4H,1D4K  \n",
       "3                                                    1D4H  \n",
       "4                                               1D4H,1D4K  \n",
       "...                                                   ...  \n",
       "483776                                     1CKP,4EUT,4EUT  \n",
       "483777                                               4EUT  \n",
       "483778                                     1CKP,4EUT,4EUT  \n",
       "483779                                               4EUT  \n",
       "483780                                          4EUT,4EUT  \n",
       "\n",
       "[483781 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cids = df[\"cid\"].unique()\n",
    "unique_pbdid = set(\",\".join(df[\"target\"].values.flatten().tolist()).split(\",\"))\n",
    "pbdid_dict = {v:k for k, v in dict(enumerate(unique_pbdid)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 3/483781 [00:00<5:00:11, 26.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "print(\"Preparing Data\")\n",
    "for cid in tqdm(cids, total=len(cids), leave=False):\n",
    "    indices = np.where(df[\"cid\"] == cid)[0]\n",
    "    xi = df.iloc[indices, 1:-1].values\n",
    "    X.append(xi)\n",
    "    yi = np.zeros(len(pbdid_dict))\n",
    "    targets = \",\".join(df.iloc[indices, -1].values.tolist()).split(\",\")\n",
    "    targets = [pbdid_dict[_id] for _id in targets if _id != \"\"]\n",
    "    yi[targets] = 1\n",
    "    y.append(yi)\n",
    "\n",
    "X = np.array(X).reshape(-1, 32)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "y = np.array(y)\n",
    "\n",
    "np.save('X_1.npy',X)\n",
    "np.save('y_1.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.94 GiB for an array with shape (483781, 2186) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-a57cbd10f93c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.94 GiB for an array with shape (483781, 2186) and data type int32"
     ]
    }
   ],
   "source": [
    "y1 = np.array(y,np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(r'C:\\Users\\reekithak\\train0\\X0.npy') ; y = np.load(r\"C:\\Users\\reekithak\\train0\\y0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, x_v, y_t, y_v = train_test_split(X, y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound \n",
    "  \n",
    "freq = 100\n",
    "dur = 50\n",
    "  \n",
    "# loop iterates 5 times i.e, 5 beeps will be produced. \n",
    "for i in range(0, 5):     \n",
    "    winsound.Beep(freq, dur)     \n",
    "    freq+= 100\n",
    "    dur+= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((509983, 32), (509983, 2237))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((494683, 32), (494683, 2237))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape , y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(l, n):\n",
    "    \n",
    "    for i in range(0, len(l), n):\n",
    "        if i + n >= len(l):\n",
    "            yield l[i:len(l)]\n",
    "        else:\n",
    "            yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import tqdm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledRange = list(range(len(x_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shuffledRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITER  0\n",
      "Init_Batches =  494683\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1024, 2237) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-14455192f2c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Batch '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \"\"\"\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    805\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[0;32m    806\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reekithak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    845\u001b[0m     raise ValueError(\n\u001b[0;32m    846\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1024, 2237) instead."
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for n in range(n_iter):\n",
    "    random.shuffle(shuffledRange)\n",
    "#     x_t = x_t[shuffledRange, :]\n",
    "#     y_t = y_t[shuffledRange, :]\n",
    "    print(\"ITER \",n)\n",
    "    count = 0\n",
    "    print(\"Init_Batches = \",len(shuffledX))\n",
    "    for batch in batches(shuffledRange, 1024):\n",
    "        x_batch = x_t[batch, :]\n",
    "        y_batch = y_t[batch, :]\n",
    "        clf2.partial_fit(x_batch, y_batch)\n",
    "        print('Batch ',count)\n",
    "        count+=1\n",
    "pickle.dump(clf2,open(\"final_model.sav\",'wb'))\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(X, y, bs):\n",
    "    indices = list(range(X.shape[0]))\n",
    "    random.shuffle(indices)\n",
    "    while True:\n",
    "        for i in range(0, len(indices) - (len(indices) % bs), bs):\n",
    "            if i + bs > len(indices):\n",
    "                batch_x = X[i:, :]\n",
    "                batch_y = y[i:, :]\n",
    "            else:\n",
    "                batch_x = X[i:i+bs, :]\n",
    "                batch_y = y[i:i+bs, :]\n",
    "            yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 2237) (1024, 2237)\n"
     ]
    }
   ],
   "source": [
    "# for x_, y_ in batch_gen(X, y, bs=1024):\n",
    "#     yhat = model.predict(x_)\n",
    "#     print(yhat.shape, y_.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=(32,), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1024, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(y.shape[1], activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# model.compile(optimizer=\"adam\", loss=logits_loss, metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "EPOCHS = 50\n",
    "steps_per_epoch = x_t.shape[0] // bs\n",
    "val_steps = x_v.shape[0] // bs\n",
    "train_gen = batch_gen(x_t, y_t, bs=bs)\n",
    "val_gen = batch_gen(x_v, y_v, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "493/493 [==============================] - 92s 188ms/step - loss: 0.0114 - accuracy: 0.0789s - loss: 0.0114 - accuracy: 0.07\n",
      "Epoch 2/50\n",
      "493/493 [==============================] - 93s 188ms/step - loss: 0.0027 - accuracy: 0.3676\n",
      "Epoch 3/50\n",
      "493/493 [==============================] - 92s 187ms/step - loss: 0.0017 - accuracy: 0.5384\n",
      "Epoch 4/50\n",
      "493/493 [==============================] - 93s 188ms/step - loss: 0.0013 - accuracy: 0.6282\n",
      "Epoch 5/50\n",
      "493/493 [==============================] - 93s 189ms/step - loss: 0.0011 - accuracy: 0.6675\n",
      "Epoch 6/50\n",
      "493/493 [==============================] - 93s 189ms/step - loss: 9.6528e-04 - accuracy: 0.6958\n",
      "Epoch 7/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 8.8415e-04 - accuracy: 0.7086TA: 34s - loss: 9 - ETA: 29s -  - ETA: 22s - loss: 9.2424e-04 - accuracy: 0 - ETA: 21s - loss: 9.2157e-04 - ac - ETA: 18s - loss: 9.1394e-04  - ETA: 15s \n",
      "Epoch 8/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 8.2297e-04 - accuracy: 0.7193s - loss: 8.2297e-04 - accuracy: 0.71\n",
      "Epoch 9/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 7.8462e-04 - accuracy: 0.7233\n",
      "Epoch 10/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 7.3528e-04 - accuracy: 0.7324\n",
      "Epoch 11/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 7.0714e-04 - accuracy: 0.7339s - loss: 7.1229e-04  - ETA: 0s - loss: 7.0709e-04 - accuracy: 0.\n",
      "Epoch 12/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 6.8118e-04 - accuracy: 0.7388\n",
      "Epoch 13/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 6.5436e-04 - accuracy: 0.7420\n",
      "Epoch 14/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 6.3037e-04 - accuracy: 0.7458\n",
      "Epoch 15/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 6.0089e-04 - accuracy: 0.7484\n",
      "Epoch 16/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 5.7854e-04 - accuracy: 0.7510s - loss: 5.7911e-04 - \n",
      "Epoch 17/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 5.6578e-04 - accuracy: 0.7528\n",
      "Epoch 18/50\n",
      "493/493 [==============================] - 95s 193ms/step - loss: 5.4200e-04 - accuracy: 0.7574\n",
      "Epoch 19/50\n",
      "493/493 [==============================] - 96s 194ms/step - loss: 5.2933e-04 - accuracy: 0.7588\n",
      "Epoch 20/50\n",
      "493/493 [==============================] - 96s 195ms/step - loss: 5.2517e-04 - accuracy: 0.7598 10s - loss: 5.3121e-04  - ETA: 8s - loss: 5.2 - ETA - ETA: 1s - loss: 5.2516e\n",
      "Epoch 21/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 5.2556e-04 - accuracy: 0.7569\n",
      "Epoch 22/50\n",
      "493/493 [==============================] - 93s 189ms/step - loss: 5.0812e-04 - accuracy: 0.7586 58s - loss: 5.4462e-04 - accuracy: - ETA: 57s - loss: 5.3898e-04 - - ETA: 54s - loss: 5.3001e-0 - ETA: 50s - loss: 5.2341e-04 - accuracy: - ETA: 40s - loss: 4.927 -\n",
      "Epoch 23/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 4.9153e-04 - accuracy: 0.7606 14s - loss: 4.9625e-04 - - ETA: 11s - loss: 4.9521e-04 - \n",
      "Epoch 24/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 4.7698e-04 - accuracy: 0.7620\n",
      "Epoch 25/50\n",
      "493/493 [==============================] - 95s 193ms/step - loss: 4.7128e-04 - accuracy: 0.7637\n",
      "Epoch 26/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 4.6304e-04 - accuracy: 0.7652\n",
      "Epoch 27/50\n",
      "493/493 [==============================] - 94s 192ms/step - loss: 4.5214e-04 - accuracy: 0.7651 20s - loss: 4.4902e - ETA: \n",
      "Epoch 28/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 4.4664e-04 - accuracy: 0.7675\n",
      "Epoch 29/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 4.3417e-04 - accuracy: 0.7691\n",
      "Epoch 30/50\n",
      "493/493 [==============================] - 93s 189ms/step - loss: 4.2789e-04 - accuracy: 0.7691\n",
      "Epoch 31/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 4.2019e-04 - accuracy: 0.7714\n",
      "Epoch 32/50\n",
      "493/493 [==============================] - 95s 193ms/step - loss: 4.1972e-04 - accuracy: 0.7692\n",
      "Epoch 33/50\n",
      "493/493 [==============================] - 95s 193ms/step - loss: 4.1485e-04 - accuracy: 0.7698\n",
      "Epoch 34/50\n",
      "493/493 [==============================] - 95s 193ms/step - loss: 4.1197e-04 - accuracy: 0.7700 20s - loss: 3.9540e-04 - accuracy:  - ETA: 19s - loss: 3.9756e- - ETA: 15s - loss: 4 - ETA: 10s - l - ETA: 6s - loss: 4.119\n",
      "Epoch 35/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 4.0213e-04 - accuracy: 0.7723s - loss: 4.0215e-04 - accuracy - ETA: 3s -\n",
      "Epoch 36/50\n",
      "493/493 [==============================] - 93s 189ms/step - loss: 4.0171e-04 - accuracy: 0.7713\n",
      "Epoch 37/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 4.0404e-04 - accuracy: 0.7714\n",
      "Epoch 38/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 4.0343e-04 - accuracy: 0.7711\n",
      "Epoch 39/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 3.9748e-04 - accuracy: 0.7719\n",
      "Epoch 40/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 3.9608e-04 - accuracy: 0.7730s - l\n",
      "Epoch 41/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 3.8906e-04 - accuracy: 0.7721 40s - los - ETA: \n",
      "Epoch 42/50\n",
      "493/493 [==============================] - 94s 191ms/step - loss: 3.8558e-04 - accuracy: 0.7727\n",
      "Epoch 43/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 3.8330e-04 - accuracy: 0.7723\n",
      "Epoch 44/50\n",
      "493/493 [==============================] - 93s 190ms/step - loss: 3.8278e-04 - accuracy: 0.7742\n",
      "Epoch 45/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 3.7898e-04 - accuracy: 0.7722\n",
      "Epoch 46/50\n",
      "493/493 [==============================] - 93s 189ms/step - loss: 3.7448e-04 - accuracy: 0.7747\n",
      "Epoch 47/50\n",
      "493/493 [==============================] - 94s 190ms/step - loss: 3.7506e-04 - accuracy: 0.7738\n",
      "Epoch 48/50\n",
      "493/493 [==============================] - 94s 192ms/step - loss: 3.8014e-04 - accuracy: 0.7746s - loss: 3.7755e-04 \n",
      "Epoch 49/50\n",
      "493/493 [==============================] - 95s 193ms/step - loss: 3.7010e-04 - accuracy: 0.7761s - loss: 3.612 - ETA\n",
      "Epoch 50/50\n",
      "493/493 [==============================] - 95s 192ms/step - loss: 3.6654e-04 - accuracy: 0.7766s - loss: 3.630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25819089548>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, steps_per_epoch = steps_per_epoch, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"graph0-ep50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
